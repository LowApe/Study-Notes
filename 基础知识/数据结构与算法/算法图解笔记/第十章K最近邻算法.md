# K最近邻算法

本章内容

- 学习使用 K 最近邻算法**创建分类系统**
- 学习特征抽取
- 学习回归，即预测数值，如明天的股价或用户对某部电影的喜欢程度
- 学习 K 最近邻算法的应用案例和局限性

## 橙子还是柚子

有时后画橙子和柚子很难判断两者的区别，但是两者还是有区别的。一般而言，柚子更大、更红。如何判断在这个水果是橙子还是柚子呢？一种办法是看它的**邻居**

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7yl4qrt1gj30te0mun36.jpg)

> 在这三个邻居中，橙子比柚子多，因此这个水果很可能是橙子。这个说明使用 K 最近邻( k-nearest neighbours,KNN)算法进行了分类

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7yl99vxurj30ve08udiq.jpg)

## 创建推荐系统

> 假设你是 Netflix，要为用户创建一个电影推荐系统。从本质上说，这类似于前面的水果问题

你可以将用户都放在一个图表里(为什么不直接用电影)，这些用户在图表中的位置取决于其喜好，因此喜好相似的用户距离较近。假设你要向 Priyanka 推荐电影，可以找出五位与他最接近的用户，因此在对电影的喜好方面，Justin、JC、Joey、Lance 和 Chris 都与 Priyanka 差不多，因此他们喜欢的电影很可能 Priyanka 也也喜欢

通过这样的图表以后，创建推荐系统就很容易

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7ylhdxrjkj30vi07u0w9.jpg)

> ⚠️注意：还有一个重要问题没有解决。在前面的图表中，相似的用户相距较近，但如何确定两位用户的相似程度呢？

### 特征抽取

在前面的水果示例中，你根据个头和颜色来比较水果，换言之，你比较的特征是个头和颜色。现在假设有三个水果，你可**抽取它们的特征**

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7ylkm6oxpj30qg0my76x.jpg)

从图中看，水果 A 和 B 比较像。下面来度量它们有多像。计算两点的距离，可使用**毕达哥拉斯公式**

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7yner94tpj30jc0jmq5j.jpg)

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7ylvvhsznj30pg0oc42y.jpg)

这个距离公式印证了你的直觉:A 和 B 很像

假设你要比较 Netflix 用户，就需要以某种方式将它们放到图表中。因此，你需要将每位用户都转换为一组坐标，就像前面对水果所做的那样的。

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7ylycwd3nj30vi0fe79g.jpg)

这里，每位用户都使用5个数字表示。

> 在数学家看来，这里计算的是五维(而不是二维)空间中的距离，但计算公式不变

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7yneec0czj30vi03u76i.jpg)

这个距离公式很灵活，即便涉及很多数字，依然可以使用它来计算距离。这种距离指出了两组数据之间的相似程度。

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7ym5r8xy9j30v00cyjuy.jpg)

这是 Priyanka 和 Justin 的距离。通过计算的出其他两个的距离，然后比较之间的距离。这个示例说明：多给电影评分，你评论的电影越多，给你的推荐就越准确

### 回归

> 假设你不仅要向 Priyanka 推荐电影，还要预测她将给这部电影打多少分。

为此，先找出与她最近的 5 个人，并非一定要选择5个最近的邻居，也可选择 2 个、10 个或 10000 个。这就是这种算法名为 K 最近邻而不是 5 最近邻的原因。回到刚才的问题，找到你身边最近的五个人然后根据邻居打分的平均值，这就是**回归**。你将使用 KNN 来做两项基本工作--分类和回归

- 分类就是编组
- 回归就是预测结果(如一个数字)

回归很有用。假设你开了个小小的面包店，每天都做新鲜面包，需要根据如一组**特征预测**当天该烤多少条面包：

- 天气指数 1～5
- 是不是周末或节假日
- 有没有活动
- 还有一些历史数据，记录在各种不同的日子售出面包数量

上面这些特征分别对应这个格式：(天气指数，节假日，互动)=面包数

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7ynaicesvj30uw0du0yo.jpg)

通过KNN算法，其中K为4，找出与今天最接近的4个邻居。(4,1,null)=?从天气开看最接近的微 A、B、D和E，然后算出这四个面包平均值结果微 218.75，这就是今天要烤的面包数

**余弦相似度**

前面计算两位用户的距离时，使用的都是距离公式。还有更适合的公式吗？在实际工作中，经常使用**余弦相似度**。假设有两位品味类似的用户，但其中一位打分时更保守。他们都很喜欢某电影的某明星，但Paul给了5星，而 Rowan 只给 4 星。如果你使用距离公式，这两位用户不能不是邻居，虽然他们品味非常相近

余弦相似度不计算两个矢量的距离，而是比较它们的角度，因此更适合处理前面所说的情况。

### 挑选合适的特征

在挑选合适的特征方面，没有法则，你必须考虑到各种需要考虑的因素

## 机器学习介绍

KNN算法真的很有用，堪称机器学习领域的领路人！你见过一个机器学习的例子：推荐系统，下面看一些其他例子

### OCR

> OCR 指的是光学字符识别(optical character recognition),这意味着你可拍摄印刷页面的照片，计算机将自动识别出其中的文字。Google 使用 OCR 来实现图书数字化。OCR 是如何工作的呢？

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7z6olr12cj30800ay3z8.jpg)

如何自动识别出这个数字是什么呢？可使用KNN

1. 游览大量的数字图片，将这些数字的**特征提取出来**
2. 遇到新图像时，你提取该图像的特征，再找到它最近的邻居都是谁

这与前面判断水果一样。一般而言，OCR 算法提取险段、点和曲线等特征

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1g7z6shsdmhj30uy0as77c.jpg)

遇到新字符时，可从中提取相同的特征。OCR 中提取的特征要复杂得多，但再复杂的技术也是基于 KNN 等简单理念的。这些理念也可用于**语言识别**和**人脸识别**

OCR 的第一步是查看大量的数字图像并提取特征，这被称为**训练**。大部分机器学习都要有训练的步骤

### 创建垃圾邮件过滤器

垃圾邮件过滤器使用一种简单算法--朴素贝叶斯分类器(Naive Bayes classifier),你首先需要使用一些数据对这个分类器进行训练

假设你收到一封主题为“collect your million dollars now！”的邮件，这是垃圾邮件吗？你可研究这个句子中的每个单词，看看它在垃圾邮件中出现的概率是多少。例如某使用这个非常简答的模型时，发现只有单词 million 在垃圾邮件中出现过。朴素贝斯分类器能计算出邮件为垃圾邮件的概率，其应用领域与KNN相似

### 预测股票市场

使用机器学习来预测股票市场的涨跌真的很难。对于股票市场，如何挑选合适的特征呢？股票昨天涨了，今天也会涨，这样的特征合适吗又或者每年五月份股票市场都会涨，这样的预测可行吗？在根据以往的数据来预测未来方面，没有万无一失的方法。未来很难预测，由于**涉及的变量**，这几乎是不可能完成的任务

# 小结

- KNN 用于分类和回归，需要考虑最近的邻居
- 分类就是编组
- 回归就是预测结果(如数字)
- 特征抽取意味着将物品(如水果或用户)转换为一系列可比较的数字
- 能否挑选合适的特征事关 KNN 算法的成败