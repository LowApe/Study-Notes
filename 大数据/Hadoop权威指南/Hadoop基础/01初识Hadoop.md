# 初识Hadoop

[本书资料下载](https://github.com/tomwhite/hadoop-book.git)

# 数据！数据！

内容总结：

- 全球数据增长迅速，大量数据从大的机构产生
- 个人产生的数据正在快速增长
- 未来组织和企业想取得成功，不仅需要管理好自己的数据，还需要从其他组织或企业的数据中获得有价值的信息
- 有了大量数据，我们必须想方设法好好地存储和分析这些数据

# 数据的存储和分析

内容总结：

- 多年来硬盘存储容量不断提升，访问速度却没有与时俱进
- 单个硬盘读写时间过长，可以通过多个硬盘并行读写来减少读取时间
- 解决硬件故障问题，通过**冗余硬盘陈列(RAID)**🤔，Hadoop 的文件系统(Hadoop Distributed FileSystem，HDFS)也是一类，当系统故障，使用另外保存的复本
- 各种分布式系统允许结合不同来源的数据进行分析，确保正确性
	- MapReduce 该模型抽象出这些硬盘读/写问题并将其转换为对一个数据集(由键-值对组成)的计算。
- Hadoop 为我们提供一个可靠的且可扩展的存储和分析平台

# 查询所有数据

内容总结：

- MapReduce 是一个批量查询处理器，能够在合理的时间范围内处理针对整个**数据集**的动态查询
- 通过查询结果，甚至还运用这些信息来改善现有的服务

🌰例子:xx公司利用 Hadoop 处理邮件日志，通过运行 MapReduce 任务查找用户的地理分布，从而决定扩容时将新的邮件服务器放在那些 Rackspace 数据中心

# 不仅仅是批处理

内容总结：

- MapReduce 基本是一个批处理系统，并不适合交互式分析。更适合那种没有用户在现场等待查询结果的离线使用场景

- 第一个提供在线访问的组件是 **HBase**，一种使用 HDFS 做底层存储的键值存储模型。 HBase 不仅提供对**单行的**🤔在线读/写访问，还提供对数据块读写的**批操作**

- YARN(Yet Another Resource Negotiator)的出现意味着 Hadoop 有了新处理模型。YARN 是一个**集群资源管理系统**，允许任何一个分布式程序基于 Hadoop 集群的数据而运行。出现的🌰例子：

	- Interactive SQl-交互式 SQL

		> 利用 MapReduce 进行分发并且使用一个分布式查询引擎，使得在 Hadoop 上获得 SQL 查询低延迟响应的同时还能保持对大数据集规模的可扩展性。这个引擎使用指定的"总是开启"守护进程（Impala）或容器重用（Tez 上的 Hive）🤔

	- Iterative processing-迭代处理🤔

	- Stream processing-流处理

		> 流系统，如 Storm、Spark Streaming 或 Samza 使得在无边界数据流上运行实时、分布式的计算，并向 Hadoop 存储系统或外部系统发布结果成为可能

	- Search-搜索

		> Solr 搜索平台能够在 Hadoop 集群上运行，当文档加入 HDFS 后就可对其进行索引，且根据 HDFS 中存储的索引为搜索查询提供服务

# 相较于其他系统的优势

Hadoop 不是历史上第一个用于数据存储和分析的分布式系统

## 关系型数据库管理系统

内容总结：

- 计算机硬盘的寻址时间的提升远远小于传输速度的提升。寻址是将磁头移动到特定硬盘位置进行读写操作的过程，这是导致硬盘操作延迟的主要原因，而传输速度决定于硬盘的带宽🤔

- 如果数据库系统只更新一小部分记录，传统的 B 树(受限于寻址的速度)就更有优势。但数据库系统如果有大量数据更新时， B 树的效率就落后于 MapReduce，因为需要使用 “排序/合并” (sort/merge)来重建数据库

	- |          | 传统的关系型数据库                                           | MapReduce                                                    |
		| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
		| 数据大小 | GB                                                           | PB                                                           |
		| 数据存储 | 交互式和批处理                                               | 一次写入，多次读取                                           |
		| 更新     | 多次读/写                                                    | 一次写入，多次读取                                           |
		| 事务     | ACID                                                         | 无                                                           |
		| 结构     | 写时模式                                                     | 读时模式                                                     |
		| 完整性   | 高                                                           | 地                                                           |
		| 横向扩展 | 非线性的                                                     | 线性的                                                       |
		| 比较     | 适合于索引后数据集的点查询(point query)和更新，建立索引的数据库系统能够提供小规模数据的**低延迟数据检索**和**快速更新**<br />RDBMS 更适合持续更新的数据集 | 适合解决需要一批处理方式分析整个数据集的问题，尤其是一些特定目的的分析<br />MapReduce 适合一次写入、多次读取数据的应用 |

- 结构化数据-是既定格式的实体化数据，如 **XML 文档**或满足特定预定义格式的数据库表
- 半结构化数据- 比较松散，可能有格式，但经常被忽略，比如**电子表格**，每个单元格可以保存任何形式的数据
- 非结构化数据-如**纯文本或图像数据**。Hadoop 对非结构化和半结构化数据非常有效（Hadoop 中仅仅是一个文件拷贝操作）
- 关系型数据是**规范的(normalized)**，Hadoop 以及 MapReduce 中其他处理模型是可以随着数据规模**线性伸缩的**🤔。对数据分区后，函数原语(如 map 和 reduce)能够在各个分区上并行工作。这意味着，如果输入的数据量是原来的两倍，那么作业的运行时间也需要两倍。但如果集群规模扩展为原来的两倍，那么作业的运行速度却任然与原来一样快。SQL 查询一般不具备该特性

## 网格计算

内容总结：

**高性能计算(High Performance Computing，HPC)和网格计算(Grid Computing)组织**一直研究大规模数据处理，主要使用类似于**消息传递接口(Message Passing Interface,MPI)**的 API。

- 高性能计算：将作业分散到集群的各台机器上，这些机器访问存储区域网络(SAN)所组成的共享文件系统

- **数据本地化**特性是 Hadoop 数据处理的核心，并因此而获得良好的性能
- 网络带宽是数据中心环境最珍贵的资源(到处复制数据很容耗尽网络带宽)，Hadoop 通过显式网络拓扑结构来保留网络带宽



> 虽然 MPI 赋予程序员很大的控制权，但需要程序员显式处理数据流机制，包括用 C 语言构造底层的功能模块(例如套接字)和高层的数据分析算法。
>
> 而 Hadoop 则在更高层次上执行任务，即程序员仅从数据模型(如 MapReduce 的键值对)的角度考虑任务的执行，与此同时，数据流任然是隐性的

**在大规模分布式计算环境下，协调各个进程的执行是一个很大的挑战**，最困难的是合理处理系统的部分失效问题(在不知道一个远程进程是否挂了的情况下)同时还需要继续完成整个计算。

- MapReduce 这样的分布式处理框架，程序员不必操心系统失效的问题，因为框架能够检测到失败的任务并重新在正常的机器上执行。正因为采用的是**无共享(shared-nothing)**框架,MapReduce 才能够呈现出这种特性，这意味着各个任务之间是彼此独立的。



## 志愿计算

SETI(Search for Extra-Terrestrial Intelligence)搜索外星智慧生命，项目名称为 `SETI@home`，在该项目中，志愿者把自己计算机的 CPU 的空闲时间贡献出来分析无线天文望远镜的数据，借此寻找外星智慧生命信号。后面还有很多志愿计算项目

- 志愿计算项目将问题分成很多块，每一块为一个**工作单元**，发到世界各地的计算机上进行分析。
- SETI@home 问题是 CPU 高度密集的，比较适合在全球成千上万台计算机上运行，因为计算所花的时间远远超过工作单位数据的传输时间，**志愿者贡献的是 CPU 周期，而不是网络带宽**

MapReduce 有三大设计目标

1. 为只需要短短几分钟或几个小时就可以完成的作业提供服务
2. 运行于同一个内部有高速网络连接的数据中心内
3. 数据中心内的计算机都是可靠的、专门的硬件



# Apache Hadoop 发展建设

- 起源于开源网络搜索引擎 Apache Nutch

...



> 目前，Hadoop被主流企业广泛使用。在工业界，Hadoop 已经是公认的的大数据通用存储和分析平台，这一事实主要体现在大量直接使用或者间接包含 Hadoop 系统的产品

**本书结构图**

![image.png](http://ww1.sinaimg.cn/large/006rAlqhly1ga4ee9pvjsj30ro0zyhak.jpg)